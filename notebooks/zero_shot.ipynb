{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Notebook for Zero-Shot Inference with CheXzero\n",
    "This notebook walks through how to use CheXzero to perform zero-shot inference on a chest x-ray image dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from eval import evaluate, bootstrap\n",
    "from zero_shot import make, make_true_labels, run_softmax_eval\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../checkpoints/cxr-bert-linear2/checkpoint_5000.pt', '../checkpoints/cxr-bert-linear2/checkpoint_10000.pt', '../checkpoints/cxr-bert-linear2/checkpoint_15000.pt', '../checkpoints/cxr-bert-linear2/checkpoint_20000.pt', '../checkpoints/cxr-bert-linear2/checkpoint_25000.pt', '../checkpoints/cxr-bert-linear2/checkpoint_30000.pt', '../checkpoints/cxr-bert-linear2/checkpoint_35000.pt', '../checkpoints/cxr-bert-linear2/checkpoint_40000.pt', '../checkpoints/cxr-bert-linear2/checkpoint_45000.pt', '../checkpoints/cxr-bert-linear2/checkpoint.pt']\n"
     ]
    }
   ],
   "source": [
    "## Define Zero Shot Labels and Templates\n",
    "\n",
    "# ----- DIRECTORIES ------ #\n",
    "# # Padchest\n",
    "# cxr_filepath: str = '/home/ec2-user/all_raw_data/padchest/images/44_cxr.h5' # filepath of chest x-ray images (.h5)\n",
    "# cxr_true_labels_path: Optional[str] = '/home/ec2-user/all_raw_data/padchest/44_cxr_labels.csv' # (optional for evaluation) if labels are provided, provide path\n",
    "\n",
    "# CheXzero test\n",
    "cxr_filepath: str = '/home/ec2-user/CHEXLOCALIZE/CheXpert/test.h5' # filepath of chest x-ray images (.h5)\n",
    "cxr_true_labels_path: Optional[str] = '/home/ec2-user/CHEXLOCALIZE/CheXpert/test_labels_view1.csv' # (optional for evaluation) if labels are provided, provide path\n",
    "\n",
    "# # CheXzero val\n",
    "# cxr_filepath: str = '/home/ec2-user/all_raw_data/chexpert/CheXpert-v1.0-small/valid/chexpert_val.h5' # filepath of chest x-ray images (.h5)\n",
    "# cxr_true_labels_path: Optional[str] = '/home/ec2-user/all_raw_data/chexpert/CheXpert-v1.0-small/valid_view1.csv' # (optional for evaluation) if labels are provided, provide path\n",
    "\n",
    "\n",
    "model_dir: str = '../checkpoints/cxr-bert-linear2' # where pretrained models are saved (.pt) \n",
    "predictions_dir: Path = Path('../predictions') # where to save predictions\n",
    "cache_dir: str = predictions_dir / \"cached\" # where to cache ensembled predictions\n",
    "\n",
    "context_length: int = 77\n",
    "\n",
    "# ------- LABELS ------  #\n",
    "# Define labels to query each image | will return a prediction for each label\n",
    "# cxr_labels: List[str] = ['Atelectasis','Cardiomegaly', \n",
    "#                                       'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion',\n",
    "#                                       'Lung Opacity', 'No Finding','Pleural Effusion', 'Pleural Other', 'Pneumonia', \n",
    "#                                       'Pneumothorax', 'Support Devices']\n",
    "cxr_labels = ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly',\n",
    "                'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia',\n",
    "                'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other',\n",
    "                'Fracture', 'Support Devices']\n",
    "# cxr_labels = [label.lower() for label in cxr_labels]\n",
    "\n",
    "# ---- TEMPLATES ----- # \n",
    "# Define set of templates | see Figure 1 for more details                        \n",
    "cxr_pair_template: Tuple[str] = (\"{}\", \"no {}\")\n",
    "\n",
    "# ----- MODEL PATHS ------ #\n",
    "# If using ensemble, collect all model paths\n",
    "model_paths = []\n",
    "for subdir, dirs, files in os.walk(model_dir):\n",
    "    for file in files:\n",
    "        full_dir = os.path.join(subdir, file)\n",
    "        model_paths.append(full_dir)\n",
    "\n",
    "n = len(model_paths)\n",
    "# model_paths = model_paths[-3:]\n",
    "print(model_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the model on the data set using ensembled models\n",
    "def ensemble_models(\n",
    "    model_paths: List[str], \n",
    "    cxr_filepath: str, \n",
    "    cxr_labels: List[str], \n",
    "    cxr_pair_template: Tuple[str], \n",
    "    \n",
    "    cache_dir: str = None, \n",
    "    save_name: str = None,\n",
    "    change_text_encoder: bool = False,\n",
    ") -> Tuple[List[np.ndarray], np.ndarray]: \n",
    "    \"\"\"\n",
    "    Given a list of `model_paths`, ensemble model and return\n",
    "    predictions. Caches predictions at `cache_dir` if location provided.\n",
    "\n",
    "    Returns a list of each model's predictions and the averaged\n",
    "    set of predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = []\n",
    "    model_paths = sorted(model_paths) # ensure consistency of \n",
    "    for path in model_paths: # for each model\n",
    "        model_name = Path(path).stem\n",
    "\n",
    "        # load in model and `torch.DataLoader`\n",
    "        model, loader = make(\n",
    "            model_path=path, \n",
    "            cxr_filepath=cxr_filepath, \n",
    "            change_text_encoder=change_text_encoder,\n",
    "        ) \n",
    "        \n",
    "        # path to the cached prediction\n",
    "        if cache_dir is not None:\n",
    "            if save_name is not None: \n",
    "                cache_path = Path(cache_dir) / f\"{save_name}_{model_name}.npy\"\n",
    "            else: \n",
    "                cache_path = Path(cache_dir) / f\"{model_name}.npy\"\n",
    "\n",
    "        # if prediction already cached, don't recompute prediction\n",
    "        if cache_dir is not None and os.path.exists(cache_path): \n",
    "            print(\"Loading cached prediction for {}\".format(model_name))\n",
    "            y_pred = np.load(cache_path)\n",
    "        else: # cached prediction not found, compute preds\n",
    "            print(\"Inferring model {}\".format(path))\n",
    "            y_pred = run_softmax_eval(model, loader, cxr_labels, cxr_pair_template, change_text_encoder=change_text_encoder)\n",
    "            if cache_dir is not None: \n",
    "                Path(cache_dir).mkdir(exist_ok=True, parents=True)\n",
    "                np.save(file=cache_path, arr=y_pred)\n",
    "        predictions.append(y_pred)\n",
    "    \n",
    "    # compute average predictions\n",
    "    if len(predictions) > 1:\n",
    "        y_pred_avg = np.mean(predictions, axis=0)\n",
    "    else:\n",
    "        y_pred_avg = predictions[0]\n",
    "    \n",
    "    return predictions, y_pred_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../checkpoints/cxr-bert-linear2/checkpoint_5000.pt using an online model  \n",
      "Inferring model ../checkpoints/cxr-bert-linear2/checkpoint_5000.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0142c52292a4c43910c5a32189a5087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a41e9df33aa430fbfd217895eccd217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7e80f037514a1ca0d28342eddcd7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5360d579224f44c69de89267561da59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3afa8e4b2648d78738ed075e3a41c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:../checkpoints/cxr-bert-linear2/checkpoint_5000.pt,  AUC: 0.72748\n",
      "../checkpoints/cxr-bert-linear2/checkpoint_10000.pt using an online model  \n",
      "Inferring model ../checkpoints/cxr-bert-linear2/checkpoint_10000.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdaf1064e9d149c588d539d929cc76bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d20525afcc430d80f4921b35787533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0724224c0bff4ebdb49ef84f3ce304ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621714f0a9844d0abd23972ccbf84396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da91dc1e47a345a8bd528ab270af5df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:../checkpoints/cxr-bert-linear2/checkpoint_10000.pt,  AUC: 0.73634\n",
      "../checkpoints/cxr-bert-linear2/checkpoint_15000.pt using an online model  \n",
      "Loading cached prediction for checkpoint_15000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8958d1dabc244f4995df320cb241e672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:../checkpoints/cxr-bert-linear2/checkpoint_15000.pt,  AUC: 0.7827599999999999\n",
      "../checkpoints/cxr-bert-linear2/checkpoint_20000.pt using an online model  \n",
      "Loading cached prediction for checkpoint_20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d83ae47d9d44c5800e0b7ce1d2dba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:../checkpoints/cxr-bert-linear2/checkpoint_20000.pt,  AUC: 0.78698\n",
      "../checkpoints/cxr-bert-linear2/checkpoint_25000.pt using an online model  \n",
      "Loading cached prediction for checkpoint_25000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fac7e6fe4704fe8bc6ff634692e1183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:../checkpoints/cxr-bert-linear2/checkpoint_25000.pt,  AUC: 0.80612\n",
      "../checkpoints/cxr-bert-linear2/checkpoint_30000.pt using an online model  \n",
      "Inferring model ../checkpoints/cxr-bert-linear2/checkpoint_30000.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3bac3998c946118ca0448d1ff63c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054b593cb2514a748f81ea7104ab2a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129f500aba5e41ee86199195cb0c4cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68172f1abc7f428d8048ff08f68af8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fee1310bc9a478ba25a820d45d6f761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:../checkpoints/cxr-bert-linear2/checkpoint_30000.pt,  AUC: 0.8054399999999999\n",
      "../checkpoints/cxr-bert-linear2/checkpoint_35000.pt using an online model  \n",
      "Inferring model ../checkpoints/cxr-bert-linear2/checkpoint_35000.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed9888ee76c4d46a0f007b9f3812019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f8fc734b004d69a6e3d6785dc4ad55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e791b1aab64454815458a534a04093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25909c9ad964aed8aa20fac1444386e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8992fe97e3ae4f078722d3502a846a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:../checkpoints/cxr-bert-linear2/checkpoint_35000.pt,  AUC: 0.80846\n",
      "../checkpoints/cxr-bert-linear2/checkpoint_40000.pt using an online model  \n",
      "Inferring model ../checkpoints/cxr-bert-linear2/checkpoint_40000.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842a324ddc4949d6a13ffb1b68776e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae4f46a3bf244c5aa7235321ed83ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3a5fe5b683468a8abf082dbb4bb945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18273051398b4c0799c610097dce91b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce95a2adf77c44a0959fb3e974ad0cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:../checkpoints/cxr-bert-linear2/checkpoint_40000.pt,  AUC: 0.78586\n",
      "../checkpoints/cxr-bert-linear2/checkpoint_45000.pt using an online model  \n",
      "Inferring model ../checkpoints/cxr-bert-linear2/checkpoint_45000.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee76f1441b94904b24a7fafa9e4dd85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347f3ab3faa9488b80bdd6240be08a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ef44dab9304cd98c3dccd82460b93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e025868f9f437782dde9740364c54c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712d70dac9d04328b061d8b174fa637c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:../checkpoints/cxr-bert-linear2/checkpoint_45000.pt,  AUC: 0.79262\n",
      "../checkpoints/cxr-bert-linear2/checkpoint.pt using an online model  \n",
      "Loading cached prediction for checkpoint\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c679e8ba6c46a0b903b8404454e680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:../checkpoints/cxr-bert-linear2/checkpoint.pt,  AUC: 0.59192\n",
      "[['../checkpoints/cxr-bert-linear2/checkpoint_5000.pt', 0.72748], ['../checkpoints/cxr-bert-linear2/checkpoint_10000.pt', 0.73634], ['../checkpoints/cxr-bert-linear2/checkpoint_15000.pt', 0.7827599999999999], ['../checkpoints/cxr-bert-linear2/checkpoint_20000.pt', 0.78698], ['../checkpoints/cxr-bert-linear2/checkpoint_25000.pt', 0.80612], ['../checkpoints/cxr-bert-linear2/checkpoint_30000.pt', 0.8054399999999999], ['../checkpoints/cxr-bert-linear2/checkpoint_35000.pt', 0.80846], ['../checkpoints/cxr-bert-linear2/checkpoint_40000.pt', 0.78586], ['../checkpoints/cxr-bert-linear2/checkpoint_45000.pt', 0.79262], ['../checkpoints/cxr-bert-linear2/checkpoint.pt', 0.59192]]\n"
     ]
    }
   ],
   "source": [
    "# make test_true\n",
    "test_true = make_true_labels(cxr_true_labels_path=cxr_true_labels_path, cxr_labels=cxr_labels)\n",
    "\n",
    "result = []\n",
    "# Evaluate all models alone\n",
    "for path in model_paths:\n",
    "    predictions, y_pred_avg = ensemble_models(\n",
    "        model_paths=[path], \n",
    "        cxr_filepath=cxr_filepath, \n",
    "        cxr_labels=cxr_labels, \n",
    "        cxr_pair_template=cxr_pair_template, \n",
    "        cache_dir=cache_dir,\n",
    "        change_text_encoder = True,\n",
    "    )\n",
    "\n",
    "    test_pred = y_pred_avg\n",
    "\n",
    "    # evaluate model\n",
    "    cxr_results = evaluate(test_pred, test_true, cxr_labels)\n",
    "\n",
    "    # boostrap evaluations for 95% confidence intervals\n",
    "    bootstrap_results = bootstrap(test_pred, test_true, cxr_labels)\n",
    "    mAUC = np.mean(bootstrap_results[1][[\"Atelectasis_auc\", \"Cardiomegaly_auc\", \"Consolidation_auc\", \"Edema_auc\", \"Pleural Effusion_auc\"]].iloc[0, :])\n",
    "\n",
    "    print(\"Model:{},  AUC: {}\".format(path, mAUC))\n",
    "    result.append([path, mAUC])\n",
    "\n",
    "print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../checkpoints/cxr-bert/checkpoint_105000.pt using an online model  \n",
      "Argument error. Set pretrained = True. <class 'RuntimeError'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CLIP:\n\tUnexpected key(s) in state_dict: \"text_model.bert.embeddings.position_ids\", \"text_model.bert.embeddings.word_embeddings.weight\", \"text_model.bert.embeddings.position_embeddings.weight\", \"text_model.bert.embeddings.token_type_embeddings.weight\", \"text_model.bert.embeddings.LayerNorm.weight\", \"text_model.bert.embeddings.LayerNorm.bias\", \"text_model.bert.encoder.layer.0.attention.self.query.weight\", \"text_model.bert.encoder.layer.0.attention.self.query.bias\", \"text_model.bert.encoder.layer.0.attention.self.key.weight\", \"text_model.bert.encoder.layer.0.attention.self.key.bias\", \"text_model.bert.encoder.layer.0.attention.self.value.weight\", \"text_model.bert.encoder.layer.0.attention.self.value.bias\", \"text_model.bert.encoder.layer.0.attention.output.dense.weight\", \"text_model.bert.encoder.layer.0.attention.output.dense.bias\", \"text_model.bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.0.intermediate.dense.weight\", \"text_model.bert.encoder.layer.0.intermediate.dense.bias\", \"text_model.bert.encoder.layer.0.output.dense.weight\", \"text_model.bert.encoder.layer.0.output.dense.bias\", \"text_model.bert.encoder.layer.0.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.0.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.1.attention.self.query.weight\", \"text_model.bert.encoder.layer.1.attention.self.query.bias\", \"text_model.bert.encoder.layer.1.attention.self.key.weight\", \"text_model.bert.encoder.layer.1.attention.self.key.bias\", \"text_model.bert.encoder.layer.1.attention.self.value.weight\", \"text_model.bert.encoder.layer.1.attention.self.value.bias\", \"text_model.bert.encoder.layer.1.attention.output.dense.weight\", \"text_model.bert.encoder.layer.1.attention.output.dense.bias\", \"text_model.bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.1.intermediate.dense.weight\", \"text_model.bert.encoder.layer.1.intermediate.dense.bias\", \"text_model.bert.encoder.layer.1.output.dense.weight\", \"text_model.bert.encoder.layer.1.output.dense.bias\", \"text_model.bert.encoder.layer.1.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.1.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.2.attention.self.query.weight\", \"text_model.bert.encoder.layer.2.attention.self.query.bias\", \"text_model.bert.encoder.layer.2.attention.self.key.weight\", \"text_model.bert.encoder.layer.2.attention.self.key.bias\", \"text_model.bert.encoder.layer.2.attention.self.value.weight\", \"text_model.bert.encoder.layer.2.attention.self.value.bias\", \"text_model.bert.encoder.layer.2.attention.output.dense.weight\", \"text_model.bert.encoder.layer.2.attention.output.dense.bias\", \"text_model.bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.2.intermediate.dense.weight\", \"text_model.bert.encoder.layer.2.intermediate.dense.bias\", \"text_model.bert.encoder.layer.2.output.dense.weight\", \"text_model.bert.encoder.layer.2.output.dense.bias\", \"text_model.bert.encoder.layer.2.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.2.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.3.attention.self.query.weight\", \"text_model.bert.encoder.layer.3.attention.self.query.bias\", \"text_model.bert.encoder.layer.3.attention.self.key.weight\", \"text_model.bert.encoder.layer.3.attention.self.key.bias\", \"text_model.bert.encoder.layer.3.attention.self.value.weight\", \"text_model.bert.encoder.layer.3.attention.self.value.bias\", \"text_model.bert.encoder.layer.3.attention.output.dense.weight\", \"text_model.bert.encoder.layer.3.attention.output.dense.bias\", \"text_model.bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.3.intermediate.dense.weight\", \"text_model.bert.encoder.layer.3.intermediate.dense.bias\", \"text_model.bert.encoder.layer.3.output.dense.weight\", \"text_model.bert.encoder.layer.3.output.dense.bias\", \"text_model.bert.encoder.layer.3.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.3.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.4.attention.self.query.weight\", \"text_model.bert.encoder.layer.4.attention.self.query.bias\", \"text_model.bert.encoder.layer.4.attention.self.key.weight\", \"text_model.bert.encoder.layer.4.attention.self.key.bias\", \"text_model.bert.encoder.layer.4.attention.self.value.weight\", \"text_model.bert.encoder.layer.4.attention.self.value.bias\", \"text_model.bert.encoder.layer.4.attention.output.dense.weight\", \"text_model.bert.encoder.layer.4.attention.output.dense.bias\", \"text_model.bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.4.intermediate.dense.weight\", \"text_model.bert.encoder.layer.4.intermediate.dense.bias\", \"text_model.bert.encoder.layer.4.output.dense.weight\", \"text_model.bert.encoder.layer.4.output.dense.bias\", \"text_model.bert.encoder.layer.4.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.4.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.5.attention.self.query.weight\", \"text_model.bert.encoder.layer.5.attention.self.query.bias\", \"text_model.bert.encoder.layer.5.attention.self.key.weight\", \"text_model.bert.encoder.layer.5.attention.self.key.bias\", \"text_model.bert.encoder.layer.5.attention.self.value.weight\", \"text_model.bert.encoder.layer.5.attention.self.value.bias\", \"text_model.bert.encoder.layer.5.attention.output.dense.weight\", \"text_model.bert.encoder.layer.5.attention.output.dense.bias\", \"text_model.bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.5.intermediate.dense.weight\", \"text_model.bert.encoder.layer.5.intermediate.dense.bias\", \"text_model.bert.encoder.layer.5.output.dense.weight\", \"text_model.bert.encoder.layer.5.output.dense.bias\", \"text_model.bert.encoder.layer.5.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.5.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.6.attention.self.query.weight\", \"text_model.bert.encoder.layer.6.attention.self.query.bias\", \"text_model.bert.encoder.layer.6.attention.self.key.weight\", \"text_model.bert.encoder.layer.6.attention.self.key.bias\", \"text_model.bert.encoder.layer.6.attention.self.value.weight\", \"text_model.bert.encoder.layer.6.attention.self.value.bias\", \"text_model.bert.encoder.layer.6.attention.output.dense.weight\", \"text_model.bert.encoder.layer.6.attention.output.dense.bias\", \"text_model.bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.6.intermediate.dense.weight\", \"text_model.bert.encoder.layer.6.intermediate.dense.bias\", \"text_model.bert.encoder.layer.6.output.dense.weight\", \"text_model.bert.encoder.layer.6.output.dense.bias\", \"text_model.bert.encoder.layer.6.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.6.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.7.attention.self.query.weight\", \"text_model.bert.encoder.layer.7.attention.self.query.bias\", \"text_model.bert.encoder.layer.7.attention.self.key.weight\", \"text_model.bert.encoder.layer.7.attention.self.key.bias\", \"text_model.bert.encoder.layer.7.attention.self.value.weight\", \"text_model.bert.encoder.layer.7.attention.self.value.bias\", \"text_model.bert.encoder.layer.7.attention.output.dense.weight\", \"text_model.bert.encoder.layer.7.attention.output.dense.bias\", \"text_model.bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.7.intermediate.dense.weight\", \"text_model.bert.encoder.layer.7.intermediate.dense.bias\", \"text_model.bert.encoder.layer.7.output.dense.weight\", \"text_model.bert.encoder.layer.7.output.dense.bias\", \"text_model.bert.encoder.layer.7.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.7.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.8.attention.self.query.weight\", \"text_model.bert.encoder.layer.8.attention.self.query.bias\", \"text_model.bert.encoder.layer.8.attention.self.key.weight\", \"text_model.bert.encoder.layer.8.attention.self.key.bias\", \"text_model.bert.encoder.layer.8.attention.self.value.weight\", \"text_model.bert.encoder.layer.8.attention.self.value.bias\", \"text_model.bert.encoder.layer.8.attention.output.dense.weight\", \"text_model.bert.encoder.layer.8.attention.output.dense.bias\", \"text_model.bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.8.intermediate.dense.weight\", \"text_model.bert.encoder.layer.8.intermediate.dense.bias\", \"text_model.bert.encoder.layer.8.output.dense.weight\", \"text_model.bert.encoder.layer.8.output.dense.bias\", \"text_model.bert.encoder.layer.8.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.8.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.9.attention.self.query.weight\", \"text_model.bert.encoder.layer.9.attention.self.query.bias\", \"text_model.bert.encoder.layer.9.attention.self.key.weight\", \"text_model.bert.encoder.layer.9.attention.self.key.bias\", \"text_model.bert.encoder.layer.9.attention.self.value.weight\", \"text_model.bert.encoder.layer.9.attention.self.value.bias\", \"text_model.bert.encoder.layer.9.attention.output.dense.weight\", \"text_model.bert.encoder.layer.9.attention.output.dense.bias\", \"text_model.bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.9.intermediate.dense.weight\", \"text_model.bert.encoder.layer.9.intermediate.dense.bias\", \"text_model.bert.encoder.layer.9.output.dense.weight\", \"text_model.bert.encoder.layer.9.output.dense.bias\", \"text_model.bert.encoder.layer.9.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.9.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.10.attention.self.query.weight\", \"text_model.bert.encoder.layer.10.attention.self.query.bias\", \"text_model.bert.encoder.layer.10.attention.self.key.weight\", \"text_model.bert.encoder.layer.10.attention.self.key.bias\", \"text_model.bert.encoder.layer.10.attention.self.value.weight\", \"text_model.bert.encoder.layer.10.attention.self.value.bias\", \"text_model.bert.encoder.layer.10.attention.output.dense.weight\", \"text_model.bert.encoder.layer.10.attention.output.dense.bias\", \"text_model.bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.10.intermediate.dense.weight\", \"text_model.bert.encoder.layer.10.intermediate.dense.bias\", \"text_model.bert.encoder.layer.10.output.dense.weight\", \"text_model.bert.encoder.layer.10.output.dense.bias\", \"text_model.bert.encoder.layer.10.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.10.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.11.attention.self.query.weight\", \"text_model.bert.encoder.layer.11.attention.self.query.bias\", \"text_model.bert.encoder.layer.11.attention.self.key.weight\", \"text_model.bert.encoder.layer.11.attention.self.key.bias\", \"text_model.bert.encoder.layer.11.attention.self.value.weight\", \"text_model.bert.encoder.layer.11.attention.self.value.bias\", \"text_model.bert.encoder.layer.11.attention.output.dense.weight\", \"text_model.bert.encoder.layer.11.attention.output.dense.bias\", \"text_model.bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.11.intermediate.dense.weight\", \"text_model.bert.encoder.layer.11.intermediate.dense.bias\", \"text_model.bert.encoder.layer.11.output.dense.weight\", \"text_model.bert.encoder.layer.11.output.dense.bias\", \"text_model.bert.encoder.layer.11.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.11.output.LayerNorm.bias\", \"text_model.cls.predictions.bias\", \"text_model.cls.predictions.transform.dense.weight\", \"text_model.cls.predictions.transform.dense.bias\", \"text_model.cls.predictions.transform.LayerNorm.weight\", \"text_model.cls.predictions.transform.LayerNorm.bias\", \"text_model.cls.predictions.decoder.weight\", \"text_model.cls.predictions.decoder.bias\", \"text_model.cls_projection_head.dense_to_hidden.weight\", \"text_model.cls_projection_head.dense_to_hidden.bias\", \"text_model.cls_projection_head.LayerNorm.weight\", \"text_model.cls_projection_head.LayerNorm.bias\", \"text_model.cls_projection_head.dense_to_output.weight\", \"text_model.cls_projection_head.dense_to_output.bias\", \"text_model_linear.weight\", \"text_model_linear.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions, y_pred_avg \u001b[39m=\u001b[39m ensemble_models(\n\u001b[1;32m      2\u001b[0m     model_paths\u001b[39m=\u001b[39;49mmodel_paths, \n\u001b[1;32m      3\u001b[0m     cxr_filepath\u001b[39m=\u001b[39;49mcxr_filepath, \n\u001b[1;32m      4\u001b[0m     cxr_labels\u001b[39m=\u001b[39;49mcxr_labels, \n\u001b[1;32m      5\u001b[0m     cxr_pair_template\u001b[39m=\u001b[39;49mcxr_pair_template, \n\u001b[1;32m      6\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m      7\u001b[0m     change_text_encoder \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      8\u001b[0m )\n",
      "Cell \u001b[0;32mIn [32], line 25\u001b[0m, in \u001b[0;36mensemble_models\u001b[0;34m(model_paths, cxr_filepath, cxr_labels, cxr_pair_template, cache_dir, save_name, change_text_encoder)\u001b[0m\n\u001b[1;32m     22\u001b[0m model_name \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mstem\n\u001b[1;32m     24\u001b[0m \u001b[39m# load in model and `torch.DataLoader`\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m model, loader \u001b[39m=\u001b[39m make(\n\u001b[1;32m     26\u001b[0m     model_path\u001b[39m=\u001b[39;49mpath, \n\u001b[1;32m     27\u001b[0m     cxr_filepath\u001b[39m=\u001b[39;49mcxr_filepath, \n\u001b[1;32m     28\u001b[0m     change_text_encoder\u001b[39m=\u001b[39;49mchange_text_encoder,\n\u001b[1;32m     29\u001b[0m ) \n\u001b[1;32m     31\u001b[0m \u001b[39m# path to the cached prediction\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m cache_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/CheXzero/notebooks/../zero_shot.py:395\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(model_path, cxr_filepath, pretrained, context_length, change_text_encoder)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[39mFUNCTION: make\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m-------------------------------------------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mReturns model, data loader. \u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[39m# load model\u001b[39;00m\n\u001b[0;32m--> 395\u001b[0m model \u001b[39m=\u001b[39m load_clip(\n\u001b[1;32m    396\u001b[0m     model_path\u001b[39m=\u001b[39;49mmodel_path, \n\u001b[1;32m    397\u001b[0m     pretrained\u001b[39m=\u001b[39;49mpretrained, \n\u001b[1;32m    398\u001b[0m     context_length\u001b[39m=\u001b[39;49mcontext_length,\n\u001b[1;32m    399\u001b[0m     change_text_encoder\u001b[39m=\u001b[39;49mchange_text_encoder,\n\u001b[1;32m    400\u001b[0m )\n\u001b[1;32m    402\u001b[0m \u001b[39m# load data\u001b[39;00m\n\u001b[1;32m    403\u001b[0m transformations \u001b[39m=\u001b[39m [\n\u001b[1;32m    404\u001b[0m     \u001b[39m# means computed from sample in `cxr_stats` notebook\u001b[39;00m\n\u001b[1;32m    405\u001b[0m     Normalize((\u001b[39m101.48761\u001b[39m, \u001b[39m101.48761\u001b[39m, \u001b[39m101.48761\u001b[39m), (\u001b[39m83.43944\u001b[39m, \u001b[39m83.43944\u001b[39m, \u001b[39m83.43944\u001b[39m)),\n\u001b[1;32m    406\u001b[0m ]\n",
      "File \u001b[0;32m~/CheXzero/notebooks/../zero_shot.py:100\u001b[0m, in \u001b[0;36mload_clip\u001b[0;34m(model_path, pretrained, context_length, change_text_encoder)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[39mprint\u001b[39m(model_path,\u001b[39m\"\u001b[39m\u001b[39musing an online model  \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m     \u001b[39m# model=torch.load(model_path).to(device)\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(model_path))\n\u001b[1;32m    101\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    102\u001b[0m \u001b[39mexcept\u001b[39;00m: \n",
      "File \u001b[0;32m/opt/conda/envs/cs197proj/lib/python3.9/site-packages/torch/nn/modules/module.py:1482\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   1478\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1479\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1481\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1482\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1483\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1484\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CLIP:\n\tUnexpected key(s) in state_dict: \"text_model.bert.embeddings.position_ids\", \"text_model.bert.embeddings.word_embeddings.weight\", \"text_model.bert.embeddings.position_embeddings.weight\", \"text_model.bert.embeddings.token_type_embeddings.weight\", \"text_model.bert.embeddings.LayerNorm.weight\", \"text_model.bert.embeddings.LayerNorm.bias\", \"text_model.bert.encoder.layer.0.attention.self.query.weight\", \"text_model.bert.encoder.layer.0.attention.self.query.bias\", \"text_model.bert.encoder.layer.0.attention.self.key.weight\", \"text_model.bert.encoder.layer.0.attention.self.key.bias\", \"text_model.bert.encoder.layer.0.attention.self.value.weight\", \"text_model.bert.encoder.layer.0.attention.self.value.bias\", \"text_model.bert.encoder.layer.0.attention.output.dense.weight\", \"text_model.bert.encoder.layer.0.attention.output.dense.bias\", \"text_model.bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.0.intermediate.dense.weight\", \"text_model.bert.encoder.layer.0.intermediate.dense.bias\", \"text_model.bert.encoder.layer.0.output.dense.weight\", \"text_model.bert.encoder.layer.0.output.dense.bias\", \"text_model.bert.encoder.layer.0.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.0.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.1.attention.self.query.weight\", \"text_model.bert.encoder.layer.1.attention.self.query.bias\", \"text_model.bert.encoder.layer.1.attention.self.key.weight\", \"text_model.bert.encoder.layer.1.attention.self.key.bias\", \"text_model.bert.encoder.layer.1.attention.self.value.weight\", \"text_model.bert.encoder.layer.1.attention.self.value.bias\", \"text_model.bert.encoder.layer.1.attention.output.dense.weight\", \"text_model.bert.encoder.layer.1.attention.output.dense.bias\", \"text_model.bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.1.intermediate.dense.weight\", \"text_model.bert.encoder.layer.1.intermediate.dense.bias\", \"text_model.bert.encoder.layer.1.output.dense.weight\", \"text_model.bert.encoder.layer.1.output.dense.bias\", \"text_model.bert.encoder.layer.1.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.1.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.2.attention.self.query.weight\", \"text_model.bert.encoder.layer.2.attention.self.query.bias\", \"text_model.bert.encoder.layer.2.attention.self.key.weight\", \"text_model.bert.encoder.layer.2.attention.self.key.bias\", \"text_model.bert.encoder.layer.2.attention.self.value.weight\", \"text_model.bert.encoder.layer.2.attention.self.value.bias\", \"text_model.bert.encoder.layer.2.attention.output.dense.weight\", \"text_model.bert.encoder.layer.2.attention.output.dense.bias\", \"text_model.bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.2.intermediate.dense.weight\", \"text_model.bert.encoder.layer.2.intermediate.dense.bias\", \"text_model.bert.encoder.layer.2.output.dense.weight\", \"text_model.bert.encoder.layer.2.output.dense.bias\", \"text_model.bert.encoder.layer.2.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.2.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.3.attention.self.query.weight\", \"text_model.bert.encoder.layer.3.attention.self.query.bias\", \"text_model.bert.encoder.layer.3.attention.self.key.weight\", \"text_model.bert.encoder.layer.3.attention.self.key.bias\", \"text_model.bert.encoder.layer.3.attention.self.value.weight\", \"text_model.bert.encoder.layer.3.attention.self.value.bias\", \"text_model.bert.encoder.layer.3.attention.output.dense.weight\", \"text_model.bert.encoder.layer.3.attention.output.dense.bias\", \"text_model.bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.3.intermediate.dense.weight\", \"text_model.bert.encoder.layer.3.intermediate.dense.bias\", \"text_model.bert.encoder.layer.3.output.dense.weight\", \"text_model.bert.encoder.layer.3.output.dense.bias\", \"text_model.bert.encoder.layer.3.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.3.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.4.attention.self.query.weight\", \"text_model.bert.encoder.layer.4.attention.self.query.bias\", \"text_model.bert.encoder.layer.4.attention.self.key.weight\", \"text_model.bert.encoder.layer.4.attention.self.key.bias\", \"text_model.bert.encoder.layer.4.attention.self.value.weight\", \"text_model.bert.encoder.layer.4.attention.self.value.bias\", \"text_model.bert.encoder.layer.4.attention.output.dense.weight\", \"text_model.bert.encoder.layer.4.attention.output.dense.bias\", \"text_model.bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.4.intermediate.dense.weight\", \"text_model.bert.encoder.layer.4.intermediate.dense.bias\", \"text_model.bert.encoder.layer.4.output.dense.weight\", \"text_model.bert.encoder.layer.4.output.dense.bias\", \"text_model.bert.encoder.layer.4.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.4.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.5.attention.self.query.weight\", \"text_model.bert.encoder.layer.5.attention.self.query.bias\", \"text_model.bert.encoder.layer.5.attention.self.key.weight\", \"text_model.bert.encoder.layer.5.attention.self.key.bias\", \"text_model.bert.encoder.layer.5.attention.self.value.weight\", \"text_model.bert.encoder.layer.5.attention.self.value.bias\", \"text_model.bert.encoder.layer.5.attention.output.dense.weight\", \"text_model.bert.encoder.layer.5.attention.output.dense.bias\", \"text_model.bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.5.intermediate.dense.weight\", \"text_model.bert.encoder.layer.5.intermediate.dense.bias\", \"text_model.bert.encoder.layer.5.output.dense.weight\", \"text_model.bert.encoder.layer.5.output.dense.bias\", \"text_model.bert.encoder.layer.5.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.5.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.6.attention.self.query.weight\", \"text_model.bert.encoder.layer.6.attention.self.query.bias\", \"text_model.bert.encoder.layer.6.attention.self.key.weight\", \"text_model.bert.encoder.layer.6.attention.self.key.bias\", \"text_model.bert.encoder.layer.6.attention.self.value.weight\", \"text_model.bert.encoder.layer.6.attention.self.value.bias\", \"text_model.bert.encoder.layer.6.attention.output.dense.weight\", \"text_model.bert.encoder.layer.6.attention.output.dense.bias\", \"text_model.bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.6.intermediate.dense.weight\", \"text_model.bert.encoder.layer.6.intermediate.dense.bias\", \"text_model.bert.encoder.layer.6.output.dense.weight\", \"text_model.bert.encoder.layer.6.output.dense.bias\", \"text_model.bert.encoder.layer.6.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.6.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.7.attention.self.query.weight\", \"text_model.bert.encoder.layer.7.attention.self.query.bias\", \"text_model.bert.encoder.layer.7.attention.self.key.weight\", \"text_model.bert.encoder.layer.7.attention.self.key.bias\", \"text_model.bert.encoder.layer.7.attention.self.value.weight\", \"text_model.bert.encoder.layer.7.attention.self.value.bias\", \"text_model.bert.encoder.layer.7.attention.output.dense.weight\", \"text_model.bert.encoder.layer.7.attention.output.dense.bias\", \"text_model.bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.7.intermediate.dense.weight\", \"text_model.bert.encoder.layer.7.intermediate.dense.bias\", \"text_model.bert.encoder.layer.7.output.dense.weight\", \"text_model.bert.encoder.layer.7.output.dense.bias\", \"text_model.bert.encoder.layer.7.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.7.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.8.attention.self.query.weight\", \"text_model.bert.encoder.layer.8.attention.self.query.bias\", \"text_model.bert.encoder.layer.8.attention.self.key.weight\", \"text_model.bert.encoder.layer.8.attention.self.key.bias\", \"text_model.bert.encoder.layer.8.attention.self.value.weight\", \"text_model.bert.encoder.layer.8.attention.self.value.bias\", \"text_model.bert.encoder.layer.8.attention.output.dense.weight\", \"text_model.bert.encoder.layer.8.attention.output.dense.bias\", \"text_model.bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.8.intermediate.dense.weight\", \"text_model.bert.encoder.layer.8.intermediate.dense.bias\", \"text_model.bert.encoder.layer.8.output.dense.weight\", \"text_model.bert.encoder.layer.8.output.dense.bias\", \"text_model.bert.encoder.layer.8.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.8.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.9.attention.self.query.weight\", \"text_model.bert.encoder.layer.9.attention.self.query.bias\", \"text_model.bert.encoder.layer.9.attention.self.key.weight\", \"text_model.bert.encoder.layer.9.attention.self.key.bias\", \"text_model.bert.encoder.layer.9.attention.self.value.weight\", \"text_model.bert.encoder.layer.9.attention.self.value.bias\", \"text_model.bert.encoder.layer.9.attention.output.dense.weight\", \"text_model.bert.encoder.layer.9.attention.output.dense.bias\", \"text_model.bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.9.intermediate.dense.weight\", \"text_model.bert.encoder.layer.9.intermediate.dense.bias\", \"text_model.bert.encoder.layer.9.output.dense.weight\", \"text_model.bert.encoder.layer.9.output.dense.bias\", \"text_model.bert.encoder.layer.9.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.9.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.10.attention.self.query.weight\", \"text_model.bert.encoder.layer.10.attention.self.query.bias\", \"text_model.bert.encoder.layer.10.attention.self.key.weight\", \"text_model.bert.encoder.layer.10.attention.self.key.bias\", \"text_model.bert.encoder.layer.10.attention.self.value.weight\", \"text_model.bert.encoder.layer.10.attention.self.value.bias\", \"text_model.bert.encoder.layer.10.attention.output.dense.weight\", \"text_model.bert.encoder.layer.10.attention.output.dense.bias\", \"text_model.bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.10.intermediate.dense.weight\", \"text_model.bert.encoder.layer.10.intermediate.dense.bias\", \"text_model.bert.encoder.layer.10.output.dense.weight\", \"text_model.bert.encoder.layer.10.output.dense.bias\", \"text_model.bert.encoder.layer.10.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.10.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.11.attention.self.query.weight\", \"text_model.bert.encoder.layer.11.attention.self.query.bias\", \"text_model.bert.encoder.layer.11.attention.self.key.weight\", \"text_model.bert.encoder.layer.11.attention.self.key.bias\", \"text_model.bert.encoder.layer.11.attention.self.value.weight\", \"text_model.bert.encoder.layer.11.attention.self.value.bias\", \"text_model.bert.encoder.layer.11.attention.output.dense.weight\", \"text_model.bert.encoder.layer.11.attention.output.dense.bias\", \"text_model.bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"text_model.bert.encoder.layer.11.intermediate.dense.weight\", \"text_model.bert.encoder.layer.11.intermediate.dense.bias\", \"text_model.bert.encoder.layer.11.output.dense.weight\", \"text_model.bert.encoder.layer.11.output.dense.bias\", \"text_model.bert.encoder.layer.11.output.LayerNorm.weight\", \"text_model.bert.encoder.layer.11.output.LayerNorm.bias\", \"text_model.cls.predictions.bias\", \"text_model.cls.predictions.transform.dense.weight\", \"text_model.cls.predictions.transform.dense.bias\", \"text_model.cls.predictions.transform.LayerNorm.weight\", \"text_model.cls.predictions.transform.LayerNorm.bias\", \"text_model.cls.predictions.decoder.weight\", \"text_model.cls.predictions.decoder.bias\", \"text_model.cls_projection_head.dense_to_hidden.weight\", \"text_model.cls_projection_head.dense_to_hidden.bias\", \"text_model.cls_projection_head.LayerNorm.weight\", \"text_model.cls_projection_head.LayerNorm.bias\", \"text_model.cls_projection_head.dense_to_output.weight\", \"text_model.cls_projection_head.dense_to_output.bias\", \"text_model_linear.weight\", \"text_model_linear.bias\". "
     ]
    }
   ],
   "source": [
    "predictions, y_pred_avg = ensemble_models(\n",
    "    model_paths=model_paths, \n",
    "    cxr_filepath=cxr_filepath, \n",
    "    cxr_labels=cxr_labels, \n",
    "    cxr_pair_template=cxr_pair_template, \n",
    "    cache_dir=cache_dir,\n",
    "    change_text_encoder = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save averaged preds\n",
    "pred_name = \"chexpert_preds_bert.npy\" # add name of preds\n",
    "predictions_dir = predictions_dir / pred_name\n",
    "np.save(file=predictions_dir, arr=y_pred_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Evaluate Results\n",
    "If ground truth labels are available, compute AUC on each pathology to evaluate the performance of the zero-shot model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0c292bc43f417aa100314d2b55363a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make test_true\n",
    "test_pred = y_pred_avg\n",
    "test_true = make_true_labels(cxr_true_labels_path=cxr_true_labels_path, cxr_labels=cxr_labels)\n",
    "\n",
    "# evaluate model\n",
    "cxr_results = evaluate(test_pred, test_true, cxr_labels)\n",
    "\n",
    "# boostrap evaluations for 95% confidence intervals\n",
    "bootstrap_results = bootstrap(test_pred, test_true, cxr_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atelectasis_auc</th>\n",
       "      <th>Cardiomegaly_auc</th>\n",
       "      <th>Consolidation_auc</th>\n",
       "      <th>Edema_auc</th>\n",
       "      <th>Pleural Effusion_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.5341</td>\n",
       "      <td>0.7555</td>\n",
       "      <td>0.6241</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>0.5203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lower</th>\n",
       "      <td>0.4791</td>\n",
       "      <td>0.7090</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>0.7115</td>\n",
       "      <td>0.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>upper</th>\n",
       "      <td>0.5873</td>\n",
       "      <td>0.7973</td>\n",
       "      <td>0.7251</td>\n",
       "      <td>0.8132</td>\n",
       "      <td>0.5840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Atelectasis_auc  Cardiomegaly_auc  Consolidation_auc  Edema_auc  \\\n",
       "mean            0.5341            0.7555             0.6241     0.7631   \n",
       "lower           0.4791            0.7090             0.5144     0.7115   \n",
       "upper           0.5873            0.7973             0.7251     0.8132   \n",
       "\n",
       "       Pleural Effusion_auc  \n",
       "mean                 0.5203  \n",
       "lower                0.4555  \n",
       "upper                0.5840  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display AUC with confidence intervals\n",
    "bootstrap_results[1][[\"Atelectasis_auc\", \"Cardiomegaly_auc\", \"Consolidation_auc\", \"Edema_auc\", \"Pleural Effusion_auc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC: 0.63942\n"
     ]
    }
   ],
   "source": [
    "# top 5 competition pathologies\n",
    "print(\"Mean AUC: {}\".format(\n",
    "    np.mean(bootstrap_results[1][[\"Atelectasis_auc\", \"Cardiomegaly_auc\", \"Consolidation_auc\", \"Edema_auc\", \"Pleural Effusion_auc\"]].iloc[0, :])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(bootstrap_results[1]).to_csv('chexzero_chexpert.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs197proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6f8cabb0cdd98a043b05afebe161157b38902b348c145f12380c1bad8dc6017d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
